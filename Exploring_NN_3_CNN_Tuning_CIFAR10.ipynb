{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring CNN - Fine Tuning\n",
    "## Improving CNN Performances\n",
    "\n",
    "Exploring:\n",
    " - Data Augmentation\n",
    " - Hyperparamenter Tuning - Learning Rate\n",
    "\n",
    " Helper Functions Code Credit - Udacity DL Nanodegree Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "Here we write two functions that create appropriate transforms for the training, validation and test dataset, and then create the relative dataloaders.\n",
    "\n",
    "As usual, complete the code in the sections marked with `# YOUR CODE HERE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from torchvision import datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import random\n",
    "import multiprocessing\n",
    "from helpers import get_train_val_data_loaders, get_test_data_loader\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "# Let's write a function that gives us the transforms so we can optimize the hyperparameters\n",
    "def get_transforms(rand_augment_magnitude):\n",
    "\n",
    "    # These are the per-channel mean and std of CIFAR-10 over the dataset\n",
    "    mean = (0.49139968, 0.48215827, 0.44653124)\n",
    "    std = (0.24703233, 0.24348505, 0.26158768)\n",
    "\n",
    "    # Define our transformations\n",
    "    return {\n",
    "        \"train\": T.Compose(\n",
    "            [\n",
    "                # All images in CIFAR-10 are 32x32. We enlarge them a bit so we can then\n",
    "                # take a random crop\n",
    "                T.Resize(40),\n",
    "                \n",
    "                # take a random part of the image\n",
    "                T.RandomCrop(32),\n",
    "                \n",
    "                # Horizontal flip is not part of RandAugment according to the RandAugment\n",
    "                # paper\n",
    "                T.RandomHorizontalFlip(0.5),\n",
    "                \n",
    "                # Use RandAugment\n",
    "                # RandAugment has 2 main parameters: how many transformations should be\n",
    "                # applied to each image, and the strength of these transformations. This\n",
    "                # latter parameter should be tuned through experiments: the higher the more\n",
    "                # the regularization effect.\n",
    "                # Setup a T.RandAugment transformation using 2 as num_opts, and the\n",
    "                # rand_augment_magnitude input parameter as magnitude. \n",
    "                # Use T.InterpolationMode.BILINEAR as interpolation. Look at the pytorch\n",
    "                # manual if needed: \n",
    "                # https://pytorch.org/vision/main/generated/torchvision.transforms.RandAugment.html\n",
    "                \n",
    "                # YOUR CODE HERE\n",
    "                T.RandAugment(\n",
    "                    num_ops=2,\n",
    "                    magnitude=rand_augment_magnitude,\n",
    "                    interpolation=T.InterpolationMode.BILINEAR,\n",
    "                ),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean, std),\n",
    "            ]\n",
    "        ),\n",
    "        \"valid\": T.Compose(\n",
    "            [\n",
    "                # Both of these are useless, but we keep them because\n",
    "                # in a non-academic dataset you will need them\n",
    "                T.Resize(32),\n",
    "                T.CenterCrop(32),\n",
    "                \n",
    "                # Convert to tensor and apply normalization:\n",
    "                \n",
    "                # YOUR CODE HERE\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean, std),\n",
    "            ]\n",
    "        ),\n",
    "        # Identical to the valid set in this case\n",
    "        \"test\": T.Compose(\n",
    "            [\n",
    "                T.Resize(32),\n",
    "                T.CenterCrop(32),\n",
    "                \n",
    "                # Convert to tensor and apply normalization:\n",
    "                \n",
    "                # YOUR CODE HERE\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean, std),\n",
    "            ]\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "def get_data_loaders(batch_size, valid_size, transforms, num_workers, random_seed=42):\n",
    "    \n",
    "    # Reseed random number generators to get a deterministic split. This is useful\n",
    "    # when comparing experiments, so you'll know they all run on the same data.\n",
    "    # In principle you should repeat this a few times (cross validation) to see\n",
    "    # the variability of your measurements, but we won't do this here for simplicity\n",
    "    torch.manual_seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    # Get the CIFAR10 training dataset from torchvision.datasets and set the transforms\n",
    "    # We will split this further into train and validation in this function\n",
    "    train_data = datasets.CIFAR10(\"data\", train=True, download=True, transform=transforms['train'])\n",
    "    valid_data = datasets.CIFAR10(\"data\", train=True, download=True, transform=transforms['valid'])\n",
    "\n",
    "    # Compute how many items we will reserve for the validation set\n",
    "    n_tot = len(train_data)\n",
    "    split = int(np.floor(valid_size * n_tot))\n",
    "\n",
    "    # compute the indices for the training set and for the validation set\n",
    "    shuffled_indices = torch.randperm(n_tot)\n",
    "    train_idx, valid_idx = shuffled_indices[split:], shuffled_indices[:split]\n",
    "\n",
    "    # define samplers for obtaining training and validation batches\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    # prepare data loaders (combine dataset and sampler)\n",
    "    # NOTE that here we use train_data for the train dataloader but valid_data\n",
    "    # for the valid_loader, so the respective transforms are applied\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    test_data = datasets.CIFAR10(\"data\", train=False, download=True, transform=transforms['test'])\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_data, batch_size=batch_size, num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    return {'train': train_loader, 'valid': valid_loader, 'test': test_loader}\n",
    "\n",
    "# specify the image classes\n",
    "classes = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition\n",
    "\n",
    "Here we use a model very similar to the one we used before, but we add Batch Normalization that makes our training faster and more robust, and also allows us to go deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_classes=10):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
    "            # Add batch normalization (BatchNorm2d) here\n",
    "            # YOUR CODE HERE\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(16, 32, 3, padding=1),  # -> 32x16x16\n",
    "            # Add batch normalization (BatchNorm2d) here\n",
    "            # YOUR CODE HERE\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # -> 32x8x8\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3, padding=1),  # -> 64x8x8\n",
    "            # Add batch normalization (BatchNorm2d) here\n",
    "            # YOUR CODE HERE\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # -> 64x4x4\n",
    "            \n",
    "            # Since we are using BatchNorm and data augmentation,\n",
    "            # we can go deeper than before and add one more conv layer\n",
    "            nn.Conv2d(64, 128, 3, padding=1),  # -> 128x4x4\n",
    "            # Add batch normalization (BatchNorm2d) here\n",
    "            # YOUR CODE HERE\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # -> 128x2x2\n",
    "            \n",
    "            nn.Flatten(),  # -> 1x64x4x4\n",
    "            \n",
    "            nn.Linear(128 * 2 * 2, 500),  # -> 500\n",
    "            nn.Dropout(0.5),\n",
    "            # Add batch normalization (BatchNorm1d, NOT BatchNorm2d) here\n",
    "            # YOUR CODE HERE\n",
    "            nn.BatchNorm1d(500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Just call the model on x here:\n",
    "        # YOUR CODE HERE\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# create a complete CNN\n",
    "model = Net()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|█████████▊                     | 199/625 [00:02<00:04, 97.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.318164650783983, 2.484970506301293)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feel free to look into the code of lr_finder and see how it works!\n",
    "from lr_finder import lr_finder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 64\n",
    "valid_size = 0.2\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "transforms = get_transforms(rand_augment_magnitude=9)\n",
    "data_loaders = get_data_loaders(batch_size, valid_size, transforms, num_workers)\n",
    "\n",
    "# Range  and number of steps for the learning rate\n",
    "min_lr = 1e-5\n",
    "max_lr = 1\n",
    "n_steps = min(len(data_loaders['train']), 200)\n",
    "\n",
    "# specify loss function (categorical cross-entropy)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "losses = lr_finder(min_lr, max_lr, n_steps, loss, model, data_loaders)\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(losses.keys(), losses.values())\n",
    "plt.xscale(\"log\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"learning rate (log scale)\")\n",
    "\n",
    "# Adjust the range on the y-axis to see things more clearly\n",
    "plt.xlim([1e-4, None])\n",
    "plt.ylim([min(losses.values()), np.percentile(list(losses.values()), 97)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livelossplot import PlotLosses\n",
    "from livelossplot.outputs import MatplotlibPlot\n",
    "from helpers import train_one_epoch, valid_one_epoch\n",
    "import torch.optim\n",
    "\n",
    "\n",
    "def optimize(data_loaders, model, optimizer, loss, n_epochs, save_path, interactive_tracking=False):\n",
    "    \n",
    "    # This is a plotting function\n",
    "    def after_subplot(ax: plt.Axes, group_name: str, x_label: str):\n",
    "        \"\"\"Add title xlabel and legend to single chart\"\"\"\n",
    "        ax.set_title(group_name)\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.legend(loc=\"center right\")\n",
    "        \n",
    "    # initialize tracker for minimum validation loss\n",
    "    if interactive_tracking:\n",
    "        liveloss = PlotLosses(outputs=[MatplotlibPlot(after_subplot=after_subplot)])\n",
    "    else:\n",
    "        liveloss = None\n",
    "\n",
    "    valid_loss_min = None\n",
    "    logs = {}\n",
    "\n",
    "    # Learning rate scheduler: setup a learning rate scheduler that\n",
    "    # reduces the learning rate when the validation loss reaches a\n",
    "    # plateau. Use torch.optim.lr_scheduler.ReduceLROnPlateau, with\n",
    "    # a treshold of 0.01. Look at the docs if in doubt:\n",
    "    # https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(  # =\n",
    "        optimizer, \"min\", verbose=True, threshold=0.01  # -\n",
    "    )  # -\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        train_loss = train_one_epoch(\n",
    "            data_loaders[\"train\"], model, optimizer, loss\n",
    "        )\n",
    "\n",
    "        valid_loss = valid_one_epoch(data_loaders[\"valid\"], model, loss)\n",
    "\n",
    "        # If the validation loss decreases by more than 1%, save the model\n",
    "        if valid_loss_min is None or (\n",
    "                (valid_loss_min - valid_loss) / valid_loss_min > 0.01\n",
    "        ):\n",
    "\n",
    "            # Save the weights to save_path\n",
    "            torch.save(model.state_dict(), save_path)  # -\n",
    "\n",
    "            valid_loss_min = valid_loss\n",
    "\n",
    "        # Update learning rate, i.e., make a step in the learning rate scheduler\n",
    "        # Remember to use the validation loss, so that the learning rate scheduler\n",
    "        # will change the learning rate when the validation loss is not \n",
    "        # decreasing anymore\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        scheduler.step(valid_loss)  # -\n",
    "\n",
    "        # Log the losses and the current learning rate\n",
    "        if interactive_tracking:\n",
    "            logs[\"loss\"] = train_loss\n",
    "            logs[\"val_loss\"] = valid_loss\n",
    "            logs[\"lr\"] = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "            liveloss.update(logs)\n",
    "            liveloss.send()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
