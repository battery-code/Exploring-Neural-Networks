{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring CNN - Fine Tuning\n",
    "## Improving CNN Performances\n",
    "\n",
    "Exploring:\n",
    " - Data Augmentation\n",
    " - Hyperparamenter Tuning - Learning Rate\n",
    "\n",
    " Helper Functions Code Credit - Udacity DL Nanodegree Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Augmentation\n",
    "\n",
    "Here we write two functions that create appropriate transforms for the training, validation and test dataset, and then create the relative dataloaders.\n",
    "\n",
    "As usual, complete the code in the sections marked with `# YOUR CODE HERE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from torchvision import datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import random\n",
    "import multiprocessing\n",
    "from helpers import get_train_val_data_loaders, get_test_data_loader\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "# Let's write a function that gives us the transforms so we can optimize the hyperparameters\n",
    "def get_transforms(rand_augment_magnitude):\n",
    "\n",
    "    # These are the per-channel mean and std of CIFAR-10 over the dataset\n",
    "    mean = (0.49139968, 0.48215827, 0.44653124)\n",
    "    std = (0.24703233, 0.24348505, 0.26158768)\n",
    "\n",
    "    # Define our transformations\n",
    "    return {\n",
    "        \"train\": T.Compose(\n",
    "            [\n",
    "                # All images in CIFAR-10 are 32x32. We enlarge them a bit so we can then\n",
    "                # take a random crop\n",
    "                T.Resize(40),\n",
    "                \n",
    "                # take a random part of the image\n",
    "                T.RandomCrop(32),\n",
    "                \n",
    "                # Horizontal flip is not part of RandAugment according to the RandAugment\n",
    "                # paper\n",
    "                T.RandomHorizontalFlip(0.5),\n",
    "                \n",
    "                # Use RandAugment\n",
    "                # RandAugment has 2 main parameters: how many transformations should be\n",
    "                # applied to each image, and the strength of these transformations. This\n",
    "                # latter parameter should be tuned through experiments: the higher the more\n",
    "                # the regularization effect.\n",
    "                # Setup a T.RandAugment transformation using 2 as num_opts, and the\n",
    "                # rand_augment_magnitude input parameter as magnitude. \n",
    "                # Use T.InterpolationMode.BILINEAR as interpolation. Look at the pytorch\n",
    "                # manual if needed: \n",
    "                # https://pytorch.org/vision/main/generated/torchvision.transforms.RandAugment.html\n",
    "                \n",
    "                # YOUR CODE HERE\n",
    "                T.RandAugment(\n",
    "                    num_ops=2,\n",
    "                    magnitude=rand_augment_magnitude,\n",
    "                    interpolation=T.InterpolationMode.BILINEAR,\n",
    "                ),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean, std),\n",
    "            ]\n",
    "        ),\n",
    "        \"valid\": T.Compose(\n",
    "            [\n",
    "                # Both of these are useless, but we keep them because\n",
    "                # in a non-academic dataset you will need them\n",
    "                T.Resize(32),\n",
    "                T.CenterCrop(32),\n",
    "                \n",
    "                # Convert to tensor and apply normalization:\n",
    "                \n",
    "                # YOUR CODE HERE\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean, std),\n",
    "            ]\n",
    "        ),\n",
    "        # Identical to the valid set in this case\n",
    "        \"test\": T.Compose(\n",
    "            [\n",
    "                T.Resize(32),\n",
    "                T.CenterCrop(32),\n",
    "                \n",
    "                # Convert to tensor and apply normalization:\n",
    "                \n",
    "                # YOUR CODE HERE\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean, std),\n",
    "            ]\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "def get_data_loaders(batch_size, valid_size, transforms, num_workers, random_seed=42):\n",
    "    \n",
    "    # Reseed random number generators to get a deterministic split. This is useful\n",
    "    # when comparing experiments, so you'll know they all run on the same data.\n",
    "    # In principle you should repeat this a few times (cross validation) to see\n",
    "    # the variability of your measurements, but we won't do this here for simplicity\n",
    "    torch.manual_seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    # Get the CIFAR10 training dataset from torchvision.datasets and set the transforms\n",
    "    # We will split this further into train and validation in this function\n",
    "    train_data = datasets.CIFAR10(\"data\", train=True, download=True, transform=transforms['train'])\n",
    "    valid_data = datasets.CIFAR10(\"data\", train=True, download=True, transform=transforms['valid'])\n",
    "\n",
    "    # Compute how many items we will reserve for the validation set\n",
    "    n_tot = len(train_data)\n",
    "    split = int(np.floor(valid_size * n_tot))\n",
    "\n",
    "    # compute the indices for the training set and for the validation set\n",
    "    shuffled_indices = torch.randperm(n_tot)\n",
    "    train_idx, valid_idx = shuffled_indices[split:], shuffled_indices[:split]\n",
    "\n",
    "    # define samplers for obtaining training and validation batches\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    # prepare data loaders (combine dataset and sampler)\n",
    "    # NOTE that here we use train_data for the train dataloader but valid_data\n",
    "    # for the valid_loader, so the respective transforms are applied\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    test_data = datasets.CIFAR10(\"data\", train=False, download=True, transform=transforms['test'])\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_data, batch_size=batch_size, num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    return {'train': train_loader, 'valid': valid_loader, 'test': test_loader}\n",
    "\n",
    "# specify the image classes\n",
    "classes = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition\n",
    "\n",
    "Here we use a model very similar to the one we used before, but we add Batch Normalization that makes our training faster and more robust, and also allows us to go deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_classes=10):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
    "            # Add batch normalization (BatchNorm2d) here\n",
    "            # YOUR CODE HERE\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(16, 32, 3, padding=1),  # -> 32x16x16\n",
    "            # Add batch normalization (BatchNorm2d) here\n",
    "            # YOUR CODE HERE\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # -> 32x8x8\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3, padding=1),  # -> 64x8x8\n",
    "            # Add batch normalization (BatchNorm2d) here\n",
    "            # YOUR CODE HERE\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # -> 64x4x4\n",
    "            \n",
    "            # Since we are using BatchNorm and data augmentation,\n",
    "            # we can go deeper than before and add one more conv layer\n",
    "            nn.Conv2d(64, 128, 3, padding=1),  # -> 128x4x4\n",
    "            # Add batch normalization (BatchNorm2d) here\n",
    "            # YOUR CODE HERE\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # -> 128x2x2\n",
    "            \n",
    "            nn.Flatten(),  # -> 1x64x4x4\n",
    "            \n",
    "            nn.Linear(128 * 2 * 2, 500),  # -> 500\n",
    "            nn.Dropout(0.5),\n",
    "            # Add batch normalization (BatchNorm1d, NOT BatchNorm2d) here\n",
    "            # YOUR CODE HERE\n",
    "            nn.BatchNorm1d(500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Just call the model on x here:\n",
    "        # YOUR CODE HERE\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# create a complete CNN\n",
    "model = Net()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
