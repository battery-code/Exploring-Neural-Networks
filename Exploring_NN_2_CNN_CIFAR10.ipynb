{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Neural Networks - Phase 2 - Deeper NNs\n",
    "### Convolutional Neural Networks - CNN\n",
    "##### Basic CNN - CIFAR10\n",
    "---\n",
    "In this notebook, I train a **CNN** to classify images from the CIFAR-10 database and play around with a deep NN to learn the concepts hands-on.\n",
    "\n",
    "CNN Architecture Credits - Udacity DL Nanodegree program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions for Model Operations\n",
    " - Data Loaders\n",
    " - Defining each Training and Validation Epoch\n",
    " - Build Model: COmbine Training and Validation to fit the data\n",
    " - Testing Epoch\n",
    " - Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper Functions for Model operations\n",
    "\n",
    "# Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from livelossplot import PlotLosses\n",
    "from livelossplot.outputs import MatplotlibPlot\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader functions\n",
    "\n",
    "def get_train_val_data_loaders(batch_size, valid_size, transforms, num_workers):\n",
    "    \"\"\"\n",
    "    Purpose: Helper function for setting up the data pipeline, specifically creating separate data loaders for training and validation.\n",
    "    Need? 1) Explicitly separates train and validation data and used for all epochs so no data leakage occurs\n",
    "    2) Additional features like randomization in selection where possible 3) manage parallel processing\n",
    "    Input:  \n",
    "    -batch_size: how many images to be processed each time, \n",
    "    -valid_size: what fraction to be set aside for validation\n",
    "    -transforms: Image transformations to be applied to the dataset\n",
    "    -num_workers: Number of parallel processes for loading the data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Downloads CIFAR10 dataset if not already present\n",
    "    train_data = datasets.CIFAR10(\"data\", train=True, download=True, transform=transforms)\n",
    "\n",
    "    # We will now split into train and validation\n",
    "    # Compute how many items we will reserve for the validation set\n",
    "    n_tot = len(train_data)\n",
    "    split = int(np.floor(valid_size * n_tot))\n",
    "\n",
    "    # Splitting indices of data between training and validation randomly using randperm()\n",
    "    shuffled_indices = torch.randperm(n_tot)\n",
    "    train_idx, valid_idx = shuffled_indices[split:], shuffled_indices[:split]\n",
    "\n",
    "    # define samplers so indices of data are picked randomly for training and validation\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    # create pytorch DataLoader for training and validation\n",
    "    # DataLoader picks the data using the sampler, batches data, coordinate parallel processing, provides iterator for data\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "def get_test_data_loader(batch_size, transforms, num_workers):\n",
    "    \"\"\"\n",
    "    Purpose: Helper function for creating the data loader for testing.\n",
    "    Need? Why not included above? Practically downloads/loads the test data and need not be clubbed with training/validation which uses the same dataset \n",
    "    \"\"\"\n",
    "    # We use the entire test dataset in the test dataloader\n",
    "    test_data = datasets.CIFAR10(\"data\", train=False, download=True, transform=transforms)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_data, batch_size=batch_size, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for training and validation epochs\n",
    "# Functions to be used by another function to combine and execute the forward and backward passes\n",
    "\n",
    "def train_one_epoch(train_dataloader, model, optimizer, loss):\n",
    "    \"\"\"\n",
    "    Performs one pass with training data, updating the model's parameters along the way. \n",
    "    Input:\n",
    "        train_dataloader: Provides batches of training data\n",
    "        model: Your neural network\n",
    "        optimizer: chosen optimizer\n",
    "        loss: chosen loss function \n",
    "    Called by another function, optimize which pairs this with other functions for a complete forward and backward pass\n",
    "    \"\"\"\n",
    "\n",
    "    # GPU run Matrix computations faster but model and data,loss function must be moved to GPU to run it there\n",
    "    # if torch.cuda.is_available():\n",
    "        # model.cuda()  # model is moved while whole dataset might be too big for GPU. Will be done below in batches as needed.\n",
    "\n",
    "    # Set the model in training mode\n",
    "    # (so all layers that behave differently between training and evaluation,\n",
    "    # like batchnorm and dropout, will toggle to their training behavior)\n",
    "    model.train() # In train mode, dropout happens when it doesnt in eval mode. Batchnorm uses current batch stats while eval mode, stored values are used. Few major differences for train/eval mode.\n",
    "\n",
    "    train_loss = 0.0\n",
    "\n",
    "    # Training loop using tqdm to show a progress bar\n",
    "    # enumerate(train_dataloader) gives batch_idx, (data, target) to the for loop\n",
    "    # Remaining lines are tqdm progress bar specs\n",
    "    for batch_idx, (data, target) in tqdm(\n",
    "        enumerate(train_dataloader),\n",
    "        desc=\"Training\",\n",
    "        total=len(train_dataloader),\n",
    "        leave=True,\n",
    "        ncols=80,\n",
    "    ):\n",
    "        # move data to GPU if available\n",
    "        # if torch.cuda.is_available():\n",
    "            # data, target = data.cuda(), target.cuda() # model and data has to be moved to GPU. Data done in batches for better efficiency or whole dataset might be too big for GPU\n",
    "\n",
    "        # 1. clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()  \n",
    "        # 2. forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)  \n",
    "        # 3. calculate the loss\n",
    "        loss_value = loss(output, target)  \n",
    "        # 4. backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss_value.backward()  \n",
    "        # 5. perform a single optimization step (parameter update)\n",
    "        optimizer.step()  \n",
    "\n",
    "        # running average of the loss throughout the epoch. It's using an online formula and not storing values in a list/memory.\n",
    "        # Dynamic running average formula: new avg. = prev.avg. + (1/Batches so far) * (Current value - prev. avg.)\n",
    "        # Dynamic running average formula in words: if avg a of n number is known and then with n+1 data item, we simply add 1/(n+1)th portion of the difference between new value and prev. avg. to get the new total avg. \n",
    "        train_loss = train_loss + (\n",
    "            (1 / (batch_idx + 1)) * (loss_value.data.item() - train_loss)\n",
    "        )\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def valid_one_epoch(valid_dataloader, model, loss):\n",
    "    \"\"\"\n",
    "    Validation run of one epoch; Quite similar to train function above while major difference is that gradient tracking is toggled off and eval mode is toggled on \n",
    "    Called by another function, optimize which calls train_one_epoch and then this function for validation run and related stats\n",
    "    \"\"\"\n",
    "\n",
    "    # Gradient tracking by the Pytorch Autograd engine is turned off during validation/test data run phases to gain some memory/time efficiency. \n",
    "    # torch.no_grad() turns off grad tracking for the code within \"with\" loop after which grad tracking is back on\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # set the model to evaluation mode\n",
    "        # (so all layers that behave differently between training and evaluation,\n",
    "        # like batchnorm and dropout, will select their evaluation behavior)\n",
    "        model.eval()  # In eval mode, dropout dont happen even if defined in architecture. Batchnorm uses prev. stored values.\n",
    "\n",
    "        # If the GPU is available, move the model to the GPU\n",
    "        # if torch.cuda.is_available():\n",
    "            # model.cuda() # Only model is moved for now while whole dataset might be too big for GPU. Will be done below in batches as needed.\n",
    "\n",
    "        # Loop over the validation dataset and accumulate the loss\n",
    "        valid_loss = 0.0\n",
    "        for batch_idx, (data, target) in tqdm(\n",
    "            enumerate(valid_dataloader),\n",
    "            desc=\"Validating\",\n",
    "            total=len(valid_dataloader),\n",
    "            leave=True,\n",
    "            ncols=80,\n",
    "        ):\n",
    "            # move data to GPU if available\n",
    "            # if torch.cuda.is_available():\n",
    "                # data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # 1. forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)  # Only this computation gets done in cuda if available\n",
    "            # 2. calculate the loss\n",
    "            loss_value = loss(output, target)  # =\n",
    "\n",
    "            # Calculate average validation loss\n",
    "            valid_loss = valid_loss + (\n",
    "                (1 / (batch_idx + 1)) * (loss_value.data.item() - valid_loss)\n",
    "            )\n",
    "\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validate model while tracking relevant parameters\n",
    "\n",
    "def optimize(data_loaders, model, optimizer, loss, n_epochs, save_path, interactive_tracking=False):\n",
    "    \"\"\"\n",
    "    Purpose: trains and validates a model for given epochs while tracking and saving the best model when validation error starts to increase\n",
    "    Flow/features:  Training: Calls train_one_epoch() to train then calls valid_one_epoch() to compute validation loss.\n",
    "                    Logs losses: Prints training & validation loss after each epoch.\n",
    "                    Live loss tracking: Updates and displays real-time loss plots if enabled.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize tracker for minimum validation loss\n",
    "    if interactive_tracking:\n",
    "        liveloss = PlotLosses()\n",
    "    else:\n",
    "        liveloss = None\n",
    "\n",
    "    # Loop over the epochs and keep track of the minimum of the validation loss\n",
    "    valid_loss_min = None\n",
    "    logs = {}\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        train_loss = train_one_epoch(\n",
    "            data_loaders[\"train\"], model, optimizer, loss\n",
    "        )\n",
    "\n",
    "        valid_loss = valid_one_epoch(data_loaders[\"valid\"], model, loss)\n",
    "\n",
    "        # print training/validation statistics\n",
    "        print(\n",
    "            \"Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}\".format(\n",
    "                epoch, train_loss, valid_loss\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # If the validation loss decreases by more than 1%, save the model\n",
    "        if valid_loss_min is None or (\n",
    "                (valid_loss_min - valid_loss) / valid_loss_min > 0.01\n",
    "        ):\n",
    "            print(f\"New minimum validation loss: {valid_loss:.6f}. Saving model ...\")\n",
    "\n",
    "            # Save the weights to save_path\n",
    "            torch.save(model.state_dict(), save_path)  # -\n",
    "\n",
    "            valid_loss_min = valid_loss\n",
    "\n",
    "        # Log the losses and the current learning rate\n",
    "        if interactive_tracking:\n",
    "            logs[\"loss\"] = train_loss\n",
    "            logs[\"val_loss\"] = valid_loss\n",
    "\n",
    "            liveloss.update(logs)\n",
    "            liveloss.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing run\n",
    "\n",
    "def one_epoch_test(test_dataloader, model, loss):\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    # Gradient tracking by the Pytorch Autograd engine is turned off during validation/test data run phases to gain some memory/time efficiency. \n",
    "    # torch.no_grad() turns off grad tracking for the code within \"with\" loop outside of which grad tracking is back on\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # set the model to evaluation mode\n",
    "        model.eval()  # -\n",
    "\n",
    "        # if the GPU is available, move the model to the GPU\n",
    "        # if torch.cuda.is_available():\n",
    "            # model = model.cuda()\n",
    "\n",
    "        # Loop over test dataset\n",
    "        # We also accumulate predictions and targets so we can return them\n",
    "        preds = []\n",
    "        actuals = []\n",
    "        \n",
    "        for batch_idx, (data, target) in tqdm(\n",
    "                enumerate(test_dataloader),\n",
    "                desc='Testing',\n",
    "                total=len(test_dataloader),\n",
    "                leave=True,\n",
    "                ncols=80\n",
    "        ):\n",
    "            # move data to GPU if available\n",
    "            # if torch.cuda.is_available():\n",
    "                # data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # 1. forward pass: compute predicted outputs by passing inputs to the model\n",
    "            logits = model(data)  # output are softmax logits values and not a class name/id\n",
    "            # 2. calculate the loss\n",
    "            loss_value = loss(logits, target).detach()\n",
    "\n",
    "            # update average test loss\n",
    "            test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss_value.data.item() - test_loss))\n",
    "\n",
    "            # convert logits to predicted class\n",
    "            # NOTE: the predicted class is the index of the max of the logits which is extracted below\n",
    "            pred = logits.data.max(1, keepdim=  True)[1] \n",
    "\n",
    "            # a running total of correct preds\n",
    "            correct += torch.sum(torch.squeeze(pred.eq(target.data.view_as(pred))).cpu())\n",
    "            # running total of count of all samples processed\n",
    "            total += data.size(0)\n",
    "            \n",
    "            # Append entire list of preds and actuals to a list for later reference\n",
    "            preds.extend(pred.data.cpu().numpy().squeeze())\n",
    "            actuals.extend(target.data.view_as(pred).cpu().numpy().squeeze())\n",
    "\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n",
    "    return test_loss, preds, actuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results in confusion matrix form\n",
    "\n",
    "def plot_confusion_matrix(pred, truth, classes):\n",
    "\n",
    "    gt = pd.Series(truth, name='Ground Truth')\n",
    "    predicted = pd.Series(pred, name='Predicted')\n",
    "\n",
    "    confusion_matrix = pd.crosstab(gt, predicted)\n",
    "    confusion_matrix.index = classes\n",
    "    confusion_matrix.columns = classes\n",
    "    \n",
    "    fig, sub = plt.subplots()\n",
    "    with sns.plotting_context(\"notebook\"):\n",
    "\n",
    "        ax = sns.heatmap(\n",
    "            confusion_matrix, \n",
    "            annot=True, \n",
    "            fmt='d',\n",
    "            ax=sub, \n",
    "            linewidths=0.5, \n",
    "            linecolor='lightgray', \n",
    "            cbar=False\n",
    "        )\n",
    "        ax.set_xlabel(\"truth\")\n",
    "        ax.set_ylabel(\"pred\")\n",
    " \n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture and Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load the Data\n",
    "(Source: http://pytorch.org/docs/stable/torchvision/datasets.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [13:22<00:00, 213kB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\cifar-10-python.tar.gz to data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms\n",
    "import multiprocessing\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "# how many samples per batch to load\n",
    "batch_size = 20\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "\n",
    "# convert data to a normalized torch.FloatTensor\n",
    "transforms = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "# If you want to refresh how to load and split data in pytorch, open the helpers.py file\n",
    "# and read the code. We have documented it with comments so you can follow along easily\n",
    "train_dl, valid_dl = get_train_val_data_loaders(batch_size, valid_size, transforms, num_workers)\n",
    "test_dl = get_test_data_loader(batch_size, transforms, num_workers)\n",
    "\n",
    "# For convenience let's group them together in a dictionary\n",
    "data_loaders = {\n",
    "    'train': train_dl,\n",
    "    'valid': valid_dl,\n",
    "    'test': test_dl\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the image classes\n",
    "classes = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a Batch of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# helper function to un-normalize and display an image\n",
    "def imshow(img, sub):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    sub.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image\n",
    "    sub.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain one batch of training images\n",
    "dataiter = iter(data_loaders['train'])\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy() # convert images to numpy for display\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "# display 20 images\n",
    "# NOTE: make sure your batch size is at least 20\n",
    "fig, subs = plt.subplots(2, 10, figsize=(25, 4))\n",
    "for i, sub in enumerate(subs.flatten()):\n",
    "    imshow(images[i], sub)\n",
    "    sub.set_title(classes[labels[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View an Image in More Detail\n",
    "\n",
    "Normalized red, green, and blue (RGB) color channels as three separate, grayscale intensity images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_img = np.squeeze(images[3])\n",
    "channels = ['composite', 'red', 'green', 'blue']\n",
    "cmaps = [None, 'Reds', 'Greens', 'Blues']\n",
    "\n",
    "fig, subs = plt.subplots(1, 4) \n",
    "\n",
    "for i, sub in enumerate(subs.flatten()):\n",
    "    \n",
    "    if i == 0:\n",
    "        imshow(rgb_img, sub)\n",
    "    else:\n",
    "        img = rgb_img[i-1]\n",
    "        sub.imshow(img, cmap=cmaps[i])\n",
    "        sub.set_title(channels[i])\n",
    "        sub.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## CNN Architecture\n",
    "\n",
    "- Two Convolutional Layers with attached MaxPooling layers\n",
    "- Linear MLP + Dropout layers for the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_classes=10):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # convolutional layer 1. It sees 3x32x32 image tensor\n",
    "        # and produces 16 feature maps 32x32 (i.e., a tensor 16x32x32)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        # 2x2 pooling with stride 2. It sees tensors 16x32x32\n",
    "        # and halves their size, i.e., the output will be 16x16x16\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # convolutional layer (sees the output of the prev layer, i.e.,\n",
    "        # 16x16x16 tensor)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)  # -> 32x16x16\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # -> 32x8x8\n",
    "\n",
    "        # convolutional layer\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)  # -> 64x8x8\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)  # -> 64x4x4\n",
    "\n",
    "        # linear layer (64 * 4 * 4 -> 500)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 500)\n",
    "        self.dp1 = nn.Dropout(0.5)\n",
    "        self.rl1 = nn.ReLU()\n",
    "\n",
    "        # linear layer (500 -> 10)\n",
    "        self.fc2 = nn.Linear(500, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.relu1(self.pool1(self.conv1(x)))\n",
    "        x = self.relu2(self.pool2(self.conv2(x)))\n",
    "        x = self.relu3(self.pool3(self.conv3(x)))\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.rl1(self.dp1(self.fc1(x)))\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# We can also use nn.Sequential, which makes things a lot easier\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_classes=10):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1),  # -> 32x16x16\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # -> 32x8x8\n",
    "            nn.Conv2d(32, 64, 3, padding=1),  # -> 64x8x8\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # -> 64x4x4\n",
    "            nn.Flatten(),  # -> 1x64x4x4\n",
    "            nn.Linear(64 * 4 * 4, 500),  # -> 500\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# create a complete CNN\n",
    "model = Net()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function and Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# specify loss function (categorical cross-entropy)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train the Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize(\n",
    "    data_loaders,\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss,\n",
    "    20,\n",
    "    \"cifar10_model.pt\",\n",
    "    interactive_tracking=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test the Trained Network\n",
    "\n",
    "Test your trained model on previously unseen data! A \"good\" result will be a CNN that gets around 70% (or more, try your best!) accuracy on these test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, preds, actuals = one_epoch_test(data_loaders['valid'], model, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = plot_confusion_matrix(preds, actuals, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy by class:\\n\")\n",
    "for i, col in enumerate(cm):\n",
    "    print(f\"    {col:11s}: {cm[col][i] / cm[col].sum():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
