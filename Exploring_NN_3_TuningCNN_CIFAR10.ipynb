{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring CNN - Fine Tuning\n",
    "## Improving CNN Performances\n",
    "\n",
    "Exploring:\n",
    " - Data Augmentation\n",
    " - Hyperparamenter Tuning \n",
    "     - Learning Rate Finder\n",
    "     - Learing Rate Scheduler\n",
    "\n",
    " Helper Functions Code Credit - Udacity DL Nanodegree Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Data Augmentation\n",
    "\n",
    "Here we write two functions that create appropriate transforms for the training, validation and test dataset, and then create the relative dataloaders.\n",
    "\n",
    "As usual, complete the code in the sections marked with `# YOUR CODE HERE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from torchvision import datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import random\n",
    "import multiprocessing\n",
    "from helpers import get_train_val_data_loaders, get_test_data_loader\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "# Let's write a function that gives us the transforms so we can optimize the hyperparameters\n",
    "def get_transforms(rand_augment_magnitude):\n",
    "\n",
    "    # These are the per-channel mean and std of CIFAR-10 over the dataset\n",
    "    mean = (0.49139968, 0.48215827, 0.44653124)\n",
    "    std = (0.24703233, 0.24348505, 0.26158768)\n",
    "\n",
    "    # Define our transformations\n",
    "    return {\n",
    "        \"train\": T.Compose(\n",
    "            [\n",
    "                # All images in CIFAR-10 are 32x32. We enlarge them a bit so we can then\n",
    "                # take a random crop\n",
    "                T.Resize(40),\n",
    "                \n",
    "                # take a random part of the image\n",
    "                T.RandomCrop(32),\n",
    "                \n",
    "                # Horizontal flip is not part of RandAugment according to the RandAugment\n",
    "                # paper\n",
    "                T.RandomHorizontalFlip(0.5),\n",
    "                \n",
    "                # Use RandAugment\n",
    "                # RandAugment has 2 main parameters: how many transformations should be\n",
    "                # applied to each image, and the strength of these transformations. This\n",
    "                # latter parameter should be tuned through experiments: the higher the more\n",
    "                # the regularization effect.\n",
    "                # Setup a T.RandAugment transformation using 2 as num_opts, and the\n",
    "                # rand_augment_magnitude input parameter as magnitude. \n",
    "                # Use T.InterpolationMode.BILINEAR as interpolation. Look at the pytorch\n",
    "                # manual if needed: \n",
    "                # https://pytorch.org/vision/main/generated/torchvision.transforms.RandAugment.html\n",
    "                \n",
    "                # YOUR CODE HERE\n",
    "                T.RandAugment(\n",
    "                    num_ops=2,\n",
    "                    magnitude=rand_augment_magnitude,\n",
    "                    interpolation=T.InterpolationMode.BILINEAR,\n",
    "                ),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean, std),\n",
    "            ]\n",
    "        ),\n",
    "        \"valid\": T.Compose(\n",
    "            [\n",
    "                # Both of these are useless, but we keep them because\n",
    "                # in a non-academic dataset you will need them\n",
    "                T.Resize(32),\n",
    "                T.CenterCrop(32),\n",
    "                \n",
    "                # Convert to tensor and apply normalization:\n",
    "                \n",
    "                # YOUR CODE HERE\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean, std),\n",
    "            ]\n",
    "        ),\n",
    "        # Identical to the valid set in this case\n",
    "        \"test\": T.Compose(\n",
    "            [\n",
    "                T.Resize(32),\n",
    "                T.CenterCrop(32),\n",
    "                \n",
    "                # Convert to tensor and apply normalization:\n",
    "                \n",
    "                # YOUR CODE HERE\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean, std),\n",
    "            ]\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "def get_data_loaders(batch_size, valid_size, transforms, num_workers, random_seed=42):\n",
    "    \n",
    "    # Reseed random number generators to get a deterministic split. This is useful\n",
    "    # when comparing experiments, so you'll know they all run on the same data.\n",
    "    # In principle you should repeat this a few times (cross validation) to see\n",
    "    # the variability of your measurements, but we won't do this here for simplicity\n",
    "    torch.manual_seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    # Get the CIFAR10 training dataset from torchvision.datasets and set the transforms\n",
    "    # We will split this further into train and validation in this function\n",
    "    train_data = datasets.CIFAR10(\"data\", train=True, download=True, transform=transforms['train'])\n",
    "    valid_data = datasets.CIFAR10(\"data\", train=True, download=True, transform=transforms['valid'])\n",
    "\n",
    "    # Compute how many items we will reserve for the validation set\n",
    "    n_tot = len(train_data)\n",
    "    split = int(np.floor(valid_size * n_tot))\n",
    "\n",
    "    # compute the indices for the training set and for the validation set\n",
    "    shuffled_indices = torch.randperm(n_tot)\n",
    "    train_idx, valid_idx = shuffled_indices[split:], shuffled_indices[:split]\n",
    "\n",
    "    # define samplers for obtaining training and validation batches\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    # prepare data loaders (combine dataset and sampler)\n",
    "    # NOTE that here we use train_data for the train dataloader but valid_data\n",
    "    # for the valid_loader, so the respective transforms are applied\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    test_data = datasets.CIFAR10(\"data\", train=False, download=True, transform=transforms['test'])\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_data, batch_size=batch_size, num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    return {'train': train_loader, 'valid': valid_loader, 'test': test_loader}\n",
    "\n",
    "# specify the image classes\n",
    "classes = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_classes=10):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
    "            # Add batch normalization (BatchNorm2d) here\n",
    "            # YOUR CODE HERE\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(16, 32, 3, padding=1),  # -> 32x16x16\n",
    "            # Add batch normalization (BatchNorm2d) here\n",
    "            # YOUR CODE HERE\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # -> 32x8x8\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3, padding=1),  # -> 64x8x8\n",
    "            # Add batch normalization (BatchNorm2d) here\n",
    "            # YOUR CODE HERE\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # -> 64x4x4\n",
    "            \n",
    "            # Since we are using BatchNorm and data augmentation,\n",
    "            # we can go deeper than before and add one more conv layer\n",
    "            nn.Conv2d(64, 128, 3, padding=1),  # -> 128x4x4\n",
    "            # Add batch normalization (BatchNorm2d) here\n",
    "            # YOUR CODE HERE\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # -> 128x2x2\n",
    "            \n",
    "            nn.Flatten(),  # -> 1x64x4x4\n",
    "            \n",
    "            nn.Linear(128 * 2 * 2, 500),  # -> 500\n",
    "            nn.Dropout(0.5),\n",
    "            # Add batch normalization (BatchNorm1d, NOT BatchNorm2d) here\n",
    "            # YOUR CODE HERE\n",
    "            nn.BatchNorm1d(500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Just call the model on x here:\n",
    "        # YOUR CODE HERE\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# create a complete CNN\n",
    "model = Net()\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Pre-Training Learning Rate Finder\n",
    "\n",
    "- Custom LR finder will use small amount of data (0.4% of train dataset), run it through the network with random weights (the weights will be erased before real training), use a PyTorch LR Scheduler to change the LR and finalize a decent lr. The goal is to find a stable learning rate range - a rough range\n",
    "- Empirically, lr_finder helps avoid very bad choices (like an LR that’s too high, causing divergence) if one is not used. Even though it's not perfect, it gets us into a reasonable range faster than manual tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da9e3eba30c4ed1bb347b952483461c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar-10-python.tar.gz to data\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|█████████▊                     | 199/625 [00:22<00:48,  8.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.320445707866124, 2.443653022270935)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lr_finder definition is in the lr_finder.py file\n",
    "from lr_finder import lr_finder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 64\n",
    "valid_size = 0.2\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "transforms = get_transforms(rand_augment_magnitude=9)\n",
    "data_loaders = get_data_loaders(batch_size, valid_size, transforms, num_workers)\n",
    "\n",
    "# Range  and number of steps for the learning rate\n",
    "min_lr = 1e-5\n",
    "max_lr = 1\n",
    "n_steps = min(len(data_loaders['train']), 200)\n",
    "\n",
    "# specify loss function (categorical cross-entropy)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "losses = lr_finder(min_lr, max_lr, n_steps, loss, model, data_loaders)\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(losses.keys(), losses.values())\n",
    "plt.xscale(\"log\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"learning rate (log scale)\")\n",
    "\n",
    "# Adjust the range on the y-axis to see things more clearly\n",
    "plt.xlim([1e-4, None])\n",
    "plt.ylim([min(losses.values()), np.percentile(list(losses.values()), 97)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selection of the Learning Rate\n",
    "- You do not pick the lr of the lowest loss point since it is just before loss spikes and so an unstable point. Lowest point is on the edge of divergence and using it might cause instability\n",
    "- You pick an lr at the middle of the sloping line. Left of it is flat (flat indicating slow convergence) while right shows divergence. The middle of the slope is high enough to learn fast but low enough to remain stable.\n",
    "\n",
    "##### Empirical Best Practices\n",
    "Many deep learning practitioners have found that picking a LR about 10× smaller than the min-loss LR gives the best convergence. This avoids sudden spikes while still benefiting from fast learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning Rate Scheduler + Hyperparameter Optimization\n",
    "\n",
    "Use Learning Rate Scheduler, that changes the learning rate as the training progresses.\n",
    "\n",
    "We need to include the LR Scheduler in the trainer function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livelossplot import PlotLosses\n",
    "from livelossplot.outputs import MatplotlibPlot\n",
    "from helpers import train_one_epoch, valid_one_epoch\n",
    "import torch.optim\n",
    "\n",
    "\n",
    "def cnn_trainer(data_loaders, model, optimizer, loss, n_epochs, save_path, interactive_tracking=False):\n",
    "    \n",
    "    # This is a plotting function\n",
    "    def after_subplot(ax: plt.Axes, group_name: str, x_label: str):\n",
    "        \"\"\"Add title xlabel and legend to single chart\"\"\"\n",
    "        ax.set_title(group_name)\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.legend(loc=\"center right\")\n",
    "        \n",
    "    # initialize tracker for minimum validation loss\n",
    "    if interactive_tracking:\n",
    "        liveloss = PlotLosses(outputs=[MatplotlibPlot(after_subplot=after_subplot)])\n",
    "    else:\n",
    "        liveloss = None\n",
    "\n",
    "    valid_loss_min = None\n",
    "    logs = {}\n",
    "\n",
    "    # Learning rate scheduler: setup a learning rate scheduler that\n",
    "    # reduces the learning rate when the validation loss reaches a plateau.\n",
    "    # torch.optim.lr_scheduler.ReduceLROnPlateau, with a threshold of 0.01. \n",
    "    \n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(  \n",
    "        optimizer, \"min\", verbose=True, threshold=0.01  \n",
    "    )  \n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        train_loss = train_one_epoch(\n",
    "            data_loaders[\"train\"], model, optimizer, loss\n",
    "        )\n",
    "\n",
    "        valid_loss = valid_one_epoch(data_loaders[\"valid\"], model, loss)\n",
    "\n",
    "        # If the validation loss decreases by more than 1%, save the model\n",
    "        if valid_loss_min is None or (\n",
    "                (valid_loss_min - valid_loss) / valid_loss_min > 0.01\n",
    "        ):\n",
    "\n",
    "            # Save the weights to save_path\n",
    "            torch.save(model.state_dict(), save_path)  \n",
    "\n",
    "            valid_loss_min = valid_loss\n",
    "\n",
    "        # Update learning rate, i.e., make a step in the learning rate scheduler\n",
    "        # Using validation loss, so that the lr scheduler changes lr when the validation loss is not decreasing anymore           \n",
    "        scheduler.step(valid_loss)  \n",
    "\n",
    "        # Log the losses and the current learning rate\n",
    "        if interactive_tracking:\n",
    "            logs[\"loss\"] = train_loss\n",
    "            logs[\"val_loss\"] = valid_loss\n",
    "            logs[\"lr\"] = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "            liveloss.update(logs)\n",
    "            liveloss.send()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLFLOW - Tracking parameters and experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow \n",
    "from helpers import one_epoch_test\n",
    "\n",
    "def train_one_model(learning_rate, rand_augment_magnitude, n_epochs):\n",
    "    \n",
    "    transforms = get_transforms(rand_augment_magnitude=rand_augment_magnitude)\n",
    "    data_loaders = get_data_loaders(batch_size, valid_size, transforms, num_workers)\n",
    "    model = Net()\n",
    "    \n",
    "    if train_on_gpu:\n",
    "        model.cuda()\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        cnn_trainer(data_loaders, model, optimizer, loss, n_epochs, \"best_val_loss.pt\", interactive_tracking=True)\n",
    "        \n",
    "        # Restore best validation loss\n",
    "        model.load_state_dict(torch.load('best_val_loss.pt'))\n",
    "        \n",
    "        # Test model on *validation* set\n",
    "        val_loss, preds, actuals = one_epoch_test(data_loaders['valid'], model, loss)\n",
    "        \n",
    "        # mlflow.log_param to log parameters\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "        mlflow.log_param(\"rand_augment_magnitude\", rand_augment_magnitude)\n",
    "        \n",
    "        # mlflow.log_metric to log validation loss\n",
    "        mlflow.log_metric(\"val_loss\", val_loss)\n",
    "        \n",
    "        val_accuracy = (np.array(preds)==np.array(actuals)).sum() / len(actuals)\n",
    "        \n",
    "        # mlflow to log the validation accuracy as a metric\n",
    "        mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "        \n",
    "        # mlflow.log_artifact to asve the file\n",
    "        mlflow.log_artifact(\"best_val_loss.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
